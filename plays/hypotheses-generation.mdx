---
name: Hypotheses Generation
menu: Plays
---

# Hypotheses Generation
This play is adapted from the book „Lean UX“ by Jeff Gothelf
and Josh Seiden (see references). 

## Abstract
Hypotheses generation (HG) provides the **What** in product iterations: what to **build** and what to **measure**. Plus: a release roadmap by defining all hypotheses that have to be tested. 

## When to run
Hypothesis driven development is very effective in all situations where the team is uncertain about the problem and effective solutions. 

Generating hypotheses needs to occur when creating a product as well as when starting new development cycle or to reassure the team if they are still on track in the current cycle. 

1. Initial product creation
Generating hypotheses is the last thing you do before actually starting to design a new product. There are some things you should have done before starting: 
- initial vision statement (link)
- initial mission statement (link)
- initial/basic user/customer research (link)
- initial/basic competitive analysis (link)
- initial value proposition and/or elevator pitch (link)

What can really help but is not required:
- Product Field analysis (link) to have a frame of reference for your hypotheses
- Jobs-to-be-done analysis (link) to help you come up with assumptions

2. Starting a product development cycle
There are numerous ways to structure cycles, but they all try to give the product team focus: a theme, an OKR, a part of the product, whatever. HG is the first thing you want to do, after defining scope and timeframe of your cycle. The scope of these cycles does not have to be big to warrant hypotheses driven development. Requirements from 1. still apply but should have been done anyway. 

3. Anytime you are not sure what to do next
As soon as you are unsure if your existing hypothesis backlog is still valid, you should do another round. Start from scratch and when it is time to structure and prioritize (see below), just merge your new assumptions and hypotheses with your existing ones. 

4. Anytime
If you have not worked with explicit hypotheses yet, start now. See below for why, but there is no wrong time to begin. Requirements from 1. still apply, do those first. 


## Why to run
If you are uncertain about the nature of the problem your product is supposed to tackle and/or what the best solution is, a structured set of hypotheses helps you to 
- come up with experiments to decrease the amount of uncertainty, 
- bring them in the most effective order,
- set the scope of your current product cycle, 
- align team and stakeholders and set expectations. 

This structured approach that is modelled after positivistic scientific methods, turns the discussion away from gut feeling and personal interests to a productive discussion about which questions need answers before you can move on to the next thing. 

## Roles
There is only one specific role, that of a moderator whose role is to keep the process going and set boundaries but does not contribute to the substance of the matter. 

As HG can align stakeholders around a specific scope, it should incorporate as many **relevant** perspectives as possible. That includes for example senior management, finance, marketing, support, sourcing, designers and of course development/production. Specifically bring people to the table that can **voice** uncertainties and those who can **reduce** them. 

The size of the group is the same as in standard work meetings. 5 or 7 are great, odd numbers preferred, every member above 7 makes the meeting less productive. 

## How to run 
Time: 2-8 hours, depending on the scope and relevance of the cycle and the amount of contributors. 
Material: Post-Its, sharpies, 1 or 2 whiteboards

### 1. Formulate Problem Scope
Formulate the problem scope that expresses: 
- the vision and mission of your product
- the problem you need solved (improve retention, bring MVP to market)
- measurable (quantitative or qualitative) criteria by which to measure the success of this cycle (preferably [OKRs](link))
- communicate this to the team in advance, to give them time to
- research and accumulate existing knowledge about the problem space

### 2. State Assumptions
Give everybody a fixed time to formulate as many assumptions on their own. Help them by providing asking questions like "Who is the user?" or "Do we need X to do this?". The „Lean UX“ Book has a handy worksheet that can facilitate this. Prepare appropriate questions in advance, ask them and set a time frame for each question for the team to come up with (3-5 minutes). 

### 3. Structure Assumptions by dependency
Assumptions tend to be dependent on each other. If users do not want feature X (Hypothesis: users want recommendations), we do not need to test if it is technically feasible (Hypothesis: we can provide recommendations). The goal of this step is to visualize assumption dependency. The most basic assumptions should hang on top, the dependent hypotheses below. As the moderator, start by

- identifying a central assumption and put it on top,
- let the team find find assumptions that are directly dependent on this, 
- arrange them horizontally under the first, 
- then let the team identify assumptions dependent on those, 
- if you find a more central one, put it on top, 
- ignore the order of assumptions on the same level for now and
- repeat. 

This will give you a reverse tree of assumptions. Assumptions on the same level are not yet prioritized but need to be. 

### 4. Prioritize Assumptions by Risk
To arrive at a single list of assumptions, we need to prioritize assumptions on the same level. The most important criteria are

1. **Validation**: have you already validated this? Is there prior information that validates the assumption? 
2. **Risk**: How bad would it be if we were wrong about this? 

Put up a simple matrix on the whiteboard like this and explain the axes to the team:

![assumption risk priority](../../assets/assumption-risk-priority.svg)

As the moderator, start by taking the assumptions on the top-most level. If it is one, put it on top of your final list. If there are more, let the team decide, where to put them on the matrix. If all assumptions on the same level are on the matrix, put them on the final list in the order of proximity to the top right corner. Repeat this for each level of assumptions. 

### 5. Formulate Hypotheses
These assumptions now need to be formulated as testable hypotheses. Take each assumption and bring it into the following format: 

```
We believe <measure>
will result in <outcome>
if we observe <metric>.
```

**Measure**: What is the stimulus of your test? What do you need to do or change to see the outcome? This can be Mockups, banner ads, mailings, questionnaires, whatever. Get creative. 

**Outcome**: What change do you want to see? This can be user behavior, attitudes but also system behavior or business value. 

**Metric**: Which **quantitative** metric will have to show what value or which **qualitative** metric need to show what characteristic for you to validate the assumption. Be specific. 

Start with the top assumption and put a post-it for the **measure**, **outcome** and **metric** next to it. 

### 6. Define the scope
Use any technique to define the scope of your iteration cycle by picking the hypotheses you want to validate. Time boxing has proven very effective. Just do as many as you can in the time you have, start at the top. 

##Resources
- [Lean startup. Ries, E. (2017)](https://en.wikipedia.org/wiki/The_Lean_Startup)
- [Lean UX: Applying Lean Principles to Improve User Experience. ](http://www.jeffgothelf.com/lean-ux-book/)
- [How to Implement Hypothesis-Driven Development](https://barryoreilly.com/2013/10/21/how-to-implement-hypothesis-driven-development/)
- [The Scientific Method: How to Design & Track Viral Growth Experiments](https://www.youtube.com/watch?v=0APJlxMjPw4)

##Author(s)
[Mark Jäger](http://jaeger.digital)